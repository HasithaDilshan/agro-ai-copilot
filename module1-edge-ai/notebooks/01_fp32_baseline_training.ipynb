{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment and Imports\n",
    "# Make sure you are running this in a Colab environment with GPU enabled (Runtime -> Change runtime type)\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import shutil # For potential cleanup\n",
    "\n",
    "# Install dependencies from your repo's requirements.txt\n",
    "# To ensure this works, you'll need to clone your repository first in Colab\n",
    "# or manually upload src/ and scripts/ if you can't clone.\n",
    "\n",
    "# --- IMPORTANT: CLONE YOUR REPO OR SYNC VIA DRIVE ---\n",
    "# Option A: Clone the repo directly into Colab's ephemeral environment (recommended for active development)\n",
    "# This ensures you always use the latest code from your repo.\n",
    "# Make sure to update the URL with your actual GitHub repo URL\n",
    "REPO_URL = \"https://github.com/UOM-AgroAI-Project/agro-ai-copilot.git\" # <--- CUSTOMIZE THIS TO YOUR ACTUAL REPO URL\n",
    "REPO_NAME = \"agro-ai-copilot\"\n",
    "\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    print(f\"Cloning repository: {REPO_URL}\")\n",
    "    !git clone {REPO_URL}\n",
    "    %cd {REPO_NAME}\n",
    "    # If using private repo, Colab will ask for credentials or you can set up SSH keys.\n",
    "else:\n",
    "    print(f\"Repository '{REPO_NAME}' already cloned. Pulling latest changes...\")\n",
    "    %cd {REPO_NAME}\n",
    "    !git pull origin main # Assuming your development is on main for simplicity, adjust if on feature branch\n",
    "\n",
    "# Navigate to the specific module directory\n",
    "%cd module1-edge-ai\n",
    "\n",
    "# Add project root to Python path to import from src/\n",
    "project_root_in_colab = os.getcwd() # This will be /content/agro-ai-copilot/module1-edge-ai\n",
    "if project_root_in_colab not in sys.path:\n",
    "    sys.path.insert(0, project_root_in_colab)\n",
    "\n",
    "# Install module-specific dependencies\n",
    "print(f\"Installing requirements from: {os.path.join(project_root_in_colab, 'requirements.txt')}\")\n",
    "!pip install -r requirements.txt\n",
    "!pip install opencv-python-headless # Often useful for image processing\n",
    "\n",
    "# --- IMPORTANT: MOUNT GOOGLE DRIVE ---\n",
    "# This is crucial for accessing your persistently stored data and saving models.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- DEFINE GOOGLE DRIVE PROJECT DATA PATHS (MATCHING drive_setup_project_data_dirs.ipynb) ---\n",
    "GOOGLE_DRIVE_PROJECT_ROOT = '/content/drive/MyDrive/AgroAI_Project_Data' # <--- ENSURE THIS MATCHES YOUR SETUP!\n",
    "MODULE1_DRIVE_DATA_DIR = os.path.join(GOOGLE_DRIVE_PROJECT_ROOT, 'module1_edge_ai', 'data')\n",
    "MODULE1_DRIVE_MODELS_DIR = os.path.join(GOOGLE_DRIVE_PROJECT_ROOT, 'module1_edge_ai', 'trained_models')\n",
    "\n",
    "# Verify Drive paths exist (they should if setup notebook was run)\n",
    "if not os.path.exists(MODULE1_DRIVE_DATA_DIR):\n",
    "    raise FileNotFoundError(f\"Module 1 data directory not found in Drive: {MODULE1_DRIVE_DATA_DIR}. Run setup notebook first.\")\n",
    "if not os.path.exists(MODULE1_DRIVE_MODELS_DIR):\n",
    "    raise FileNotFoundError(f\"Module 1 models directory not found in Drive: {MODULE1_DRIVE_MODELS_DIR}. Run setup notebook first.\")\n",
    "\n",
    "print(f\"Module 1 data will be accessed from: {MODULE1_DRIVE_DATA_DIR}\")\n",
    "print(f\"Module 1 models will be saved to: {MODULE1_DRIVE_MODELS_DIR}\")\n",
    "\n",
    "# Import your custom modules\n",
    "# Make sure the current directory (module1-edge-ai) and its src/ are in sys.path\n",
    "# This is handled by %cd and sys.path.insert(0, project_root_in_colab) above\n",
    "from src.data_utils import create_tf_dataset, get_class_names, prepare_dataset\n",
    "from src.models import build_fp32_efficientnet_model, IMG_SIZE\n",
    "from src.loss_functions import WeightedFocalLoss\n",
    "\n",
    "print(\"Environment setup and imports complete.\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e391109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Data Loading and Preparation (Modified for Smaller Subset)\n",
    "\n",
    "# Define paths to your PlantVillage subset generated by mvp_data_prep.ipynb\n",
    "data_base_dir = os.path.join(MODULE1_DRIVE_DATA_DIR, 'PlantVillage_Subset')\n",
    "\n",
    "train_data_dir = os.path.join(data_base_dir, 'train')\n",
    "val_data_dir = os.path.join(data_base_dir, 'val')\n",
    "test_data_dir = os.path.join(data_base_dir, 'test')\n",
    "\n",
    "if not os.path.exists(train_data_dir):\n",
    "    print(f\"Error: Training data directory not found at {train_data_dir}\")\n",
    "    print(\"Please ensure 'mvp_data_prep.ipynb' has been run successfully and data exists in Google Drive.\")\n",
    "else:\n",
    "    print(f\"Loading data from: {data_base_dir}\")\n",
    "\n",
    "BATCH_SIZE = 32 # Keep consistent\n",
    "IMG_HEIGHT, IMG_WIDTH = IMG_SIZE, IMG_SIZE # From models.py\n",
    "\n",
    "# --- NEW: Limit dataset size for faster MVP runtime ---\n",
    "# For a super quick run, limit to just a few batches or a very small percentage.\n",
    "# We'll use the .take() method after shuffling.\n",
    "SMALL_DATASET_TAKE_COUNT_TRAIN = 100 # Take only 100 batches for training (approx 3200 images)\n",
    "SMALL_DATASET_TAKE_COUNT_VAL = 20    # Take only 20 batches for validation (approx 640 images)\n",
    "SMALL_DATASET_TAKE_COUNT_TEST = 20   # Take only 20 batches for testing (approx 640 images)\n",
    "\n",
    "print(f\"WARNING: Limiting datasets to {SMALL_DATASET_TAKE_COUNT_TRAIN} training, {SMALL_DATASET_TAKE_COUNT_VAL} validation, and {SMALL_DATASET_TAKE_COUNT_TEST} test batches for faster MVP.\")\n",
    "\n",
    "# Create datasets (raw)\n",
    "train_ds_raw = create_tf_dataset(train_data_dir, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, shuffle=True)\n",
    "val_ds_raw = create_tf_dataset(val_data_dir, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, shuffle=False)\n",
    "test_ds_raw = create_tf_dataset(test_data_dir, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Get class names\n",
    "class_names = get_class_names(train_data_dir)\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {num_classes} classes: {class_names}\")\n",
    "\n",
    "# Apply preprocessing and augmentation, THEN take a subset\n",
    "train_ds = prepare_dataset(train_ds_raw, IMG_HEIGHT, IMG_WIDTH, augment=True).take(SMALL_DATASET_TAKE_COUNT_TRAIN)\n",
    "val_ds = prepare_dataset(val_ds_raw, IMG_HEIGHT, IMG_WIDTH, augment=False).take(SMALL_DATASET_TAKE_COUNT_VAL)\n",
    "test_ds = prepare_dataset(test_ds_raw, IMG_HEIGHT, IMG_WIDTH, augment=False).take(SMALL_DATASET_TAKE_COUNT_TEST)\n",
    "\n",
    "print(\"Datasets created and prepared (subsetted for MVP).\")\n",
    "\n",
    "# Optional: Visualize a batch (will show images from the subset)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(min(9, images.shape[0])): # Ensure we don't try to plot more than available images\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Model Definition and Compilation\n",
    "\n",
    "model = build_fp32_efficientnet_model(num_classes)\n",
    "model.summary()\n",
    "\n",
    "# Define alpha weights for Weighted Focal Loss (MVP: just a placeholder example)\n",
    "# For actual weighted focal loss, you'd calculate these based on your actual class frequencies.\n",
    "dummy_alpha = np.ones(num_classes) * 0.5 # Example: all classes get 0.5 weight initially\n",
    "\n",
    "# Compile the model with a potentially slightly higher learning rate for faster initial progress\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4), # Slightly higher LR\n",
    "    loss=WeightedFocalLoss(gamma=2.0, alpha=dummy_alpha),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model defined and compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Model Training (Modified for Checkpointing and Resuming)\n",
    "\n",
    "EPOCHS = 5 # Reduced number of epochs for MVP - further speed-up\n",
    "MODEL_NAME = 'fp32_mvp_baseline'\n",
    "CHECKPOINT_DIR = os.path.join(MODULE1_DRIVE_MODELS_DIR, f'{MODEL_NAME}_checkpoints')\n",
    "latest_checkpoint_path = tf.train.latest_checkpoint(CHECKPOINT_DIR)\n",
    "\n",
    "# --- Resume from Checkpoint if available ---\n",
    "initial_epoch = 0\n",
    "if latest_checkpoint_path:\n",
    "    print(f\"Found existing checkpoint: {latest_checkpoint_path}. Attempting to resume training.\")\n",
    "    try:\n",
    "        model.load_weights(latest_checkpoint_path)\n",
    "        # Determine the epoch to resume from based on checkpoint name (e.g., model.ckpt-epoch_X)\n",
    "        # This requires consistent naming, or store epoch in a separate file.\n",
    "        # For simplicity, we just load weights and set initial_epoch to 0.\n",
    "        # If using tf.keras.callbacks.ModelCheckpoint(save_weights_only=False),\n",
    "        # you can load the entire model, but then you need to manage optimizer state.\n",
    "        # For 'save_weights_only=True' and resuming, we set the optimizer state explicitly.\n",
    "        # A more robust solution involves saving epoch number explicitly.\n",
    "        print(\"Model weights loaded successfully from checkpoint.\")\n",
    "        # For a more robust resume, you'd want to store the completed epochs somewhere\n",
    "        # and load the optimizer state as well. For this MVP, we just load weights.\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint weights: {e}. Starting training from scratch.\")\n",
    "        # Optionally, remove corrupted checkpoints or directory if load fails\n",
    "        # shutil.rmtree(CHECKPOINT_DIR, ignore_errors=True)\n",
    "else:\n",
    "    print(\"No existing checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "# Define callbacks\n",
    "# ModelCheckpoint to save weights during training for resume\n",
    "# Use a format that includes epoch number and validation accuracy\n",
    "checkpoint_filepath_pattern = os.path.join(CHECKPOINT_DIR, 'model.ckpt-epoch_{epoch:04d}_val_acc_{val_accuracy:.4f}')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath_pattern,\n",
    "    save_weights_only=True, # Save only weights, good for resuming\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=False, # Save at each epoch for resume, not just best\n",
    "    save_freq='epoch', # Save after each epoch\n",
    "    verbose=0 # Suppress verbose output for each checkpoint\n",
    ")\n",
    "\n",
    "# Callback to save the BEST overall model for final use\n",
    "best_model_filepath = os.path.join(MODULE1_DRIVE_MODELS_DIR, f'{MODEL_NAME}_best_final.h5')\n",
    "best_model_save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=best_model_filepath,\n",
    "    save_weights_only=False, # Save the entire model for easy loading\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True, # Only save the model if it's the best so far\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping to prevent overfitting\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2, # Reduced patience for faster stopping\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs, resuming from epoch {initial_epoch}...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        best_model_save_callback, # This saves the 'best' version separately\n",
    "        early_stopping_callback\n",
    "    ],\n",
    "    initial_epoch=initial_epoch # Start from this epoch\n",
    ")\n",
    "\n",
    "print(f\"Training complete. Best model (overall) saved to: {best_model_filepath}\")\n",
    "print(f\"Checkpoints saved to: {CHECKPOINT_DIR}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Basic Model Evaluation on Test Set\n",
    "\n",
    "print(\"\\n--- Evaluating MVP Model on Test Set ---\")\n",
    "# Load the best saved model for evaluation (from best_model_save_callback)\n",
    "# We load from best_model_filepath, not the latest checkpoint, for final evaluation\n",
    "final_model_path_for_eval = best_model_filepath\n",
    "if not os.path.exists(final_model_path_for_eval):\n",
    "    print(f\"Warning: Best final model not found at {final_model_path_for_eval}. Attempting to load latest checkpoint instead.\")\n",
    "    final_model_path_for_eval = latest_checkpoint_path\n",
    "\n",
    "if final_model_path_for_eval:\n",
    "    try:\n",
    "        # If it's a full model save (.h5)\n",
    "        best_model_for_eval = tf.keras.models.load_model(\n",
    "            final_model_path_for_eval,\n",
    "            custom_objects={'WeightedFocalLoss': WeightedFocalLoss}\n",
    "        )\n",
    "        print(\"Best model loaded for evaluation.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best model: {e}. Attempting to rebuild model and load weights.\")\n",
    "        best_model_for_eval = build_fp32_efficientnet_model(num_classes)\n",
    "        best_model_for_eval.load_weights(final_model_path_for_eval) # Assuming it's weights only\n",
    "        best_model_for_eval.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4),\n",
    "            loss=WeightedFocalLoss(gamma=2.0, alpha=dummy_alpha),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(\"Model rebuilt and weights loaded for evaluation.\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"No model found to evaluate. Please check training and checkpoint paths.\")\n",
    "\n",
    "loss, accuracy = best_model_for_eval.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save class names to the module's data folder in Google Drive (if not already saved)\n",
    "class_names_path = os.path.join(MODULE1_DRIVE_DATA_DIR, 'class_names.txt')\n",
    "if not os.path.exists(class_names_path):\n",
    "    with open(class_names_path, 'w') as f:\n",
    "        for name in class_names:\n",
    "            f.write(f\"{name}\\n\")\n",
    "    print(f\"Class names saved to: {class_names_path}\")\n",
    "else:\n",
    "    print(f\"Class names already exist at: {class_names_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Mock Inference Example with Saved Model (Using best model)\n",
    "\n",
    "# Get one image from the test set for demonstration\n",
    "for images, labels in test_ds.take(1):\n",
    "    sample_image = images[0]\n",
    "    sample_label = labels[0]\n",
    "    break\n",
    "\n",
    "# Add a batch dimension to the single image\n",
    "sample_image_batch = tf.expand_dims(sample_image, axis=0)\n",
    "\n",
    "# Make prediction\n",
    "predictions = best_model_for_eval.predict(sample_image_batch)\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "predicted_confidence = np.max(predictions[0])\n",
    "\n",
    "print(f\"\\n--- Mock Inference ---\")\n",
    "print(f\"True Class: {class_names[sample_label.numpy()]}\")\n",
    "print(f\"Predicted Class: {class_names[predicted_class_idx]}\")\n",
    "print(f\"Predicted Confidence: {predicted_confidence:.4f}\")\n",
    "\n",
    "plt.imshow(sample_image.numpy().astype(\"uint8\"))\n",
    "plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({predicted_confidence:.2f})\\nTrue: {class_names[sample_label.numpy()]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModule 1 FP32 MVP training and basic evaluation complete (fast version)!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
