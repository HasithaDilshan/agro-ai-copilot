{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a5a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment and Imports\n",
    "# Make sure you are running this in a Colab environment with GPU enabled (Runtime -> Change runtime type)\n",
    "\n",
    "# Clone the repository (if not already mounted via Google Drive)\n",
    "# This ensures you have access to your src/ and scripts/ directories\n",
    "# !git clone https://github.com/UOM-AgroAI-Project/agro-ai-copilot.git\n",
    "# %cd agro-ai-copilot/module1-edge-ai\n",
    "\n",
    "# For now, let's assume we navigate to the right directory if running from drive\n",
    "# or manually clone/cd.\n",
    "\n",
    "# Mount Google Drive (Recommended for persistent data storage)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define project paths - ADJUST THESE BASED ON YOUR GOOGLE DRIVE SETUP!\n",
    "# Assuming 'agro-ai-copilot' is cloned/placed under MyDrive\n",
    "project_root = '/content/drive/MyDrive/agro-ai-copilot/module1-edge-ai'\n",
    "# Fallback for temporary Colab runtime if repo is not on Drive\n",
    "if not os.path.exists(project_root):\n",
    "    project_root = '/content/module1-edge-ai' # Local Colab path if not mounted/cloned to drive\n",
    "    # If running this path, you might need to manually copy src/ and scripts/\n",
    "    # or clone the repo into /content/agro-ai-copilot and adjust accordingly.\n",
    "\n",
    "# Add project_root to Python path to import from src/\n",
    "import sys\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Install dependencies\n",
    "%cd {project_root}\n",
    "!pip install -r requirements.txt\n",
    "!pip install split-folders tqdm # For data splitting notebook, if not already\n",
    "!pip install opencv-python-headless # Useful for some image processing\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import your custom modules\n",
    "from src.data_utils import create_tf_dataset, get_class_names, prepare_dataset\n",
    "from src.models import build_fp32_efficientnet_model, IMG_SIZE\n",
    "from src.loss_functions import WeightedFocalLoss\n",
    "\n",
    "print(\"Environment setup and imports complete.\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e391109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Data Loading and Preparation\n",
    "\n",
    "# Define paths to your PlantVillage subset generated by mvp_data_prep.ipynb\n",
    "# Ensure mvp_data_prep.ipynb has been run and created this structure!\n",
    "data_base_dir = os.path.join(project_root, 'data', 'PlantVillage_Subset')\n",
    "\n",
    "train_data_dir = os.path.join(data_base_dir, 'train')\n",
    "val_data_dir = os.path.join(data_base_dir, 'val')\n",
    "test_data_dir = os.path.join(data_base_dir, 'test')\n",
    "\n",
    "if not os.path.exists(train_data_dir):\n",
    "    print(f\"Error: Training data directory not found at {train_data_dir}\")\n",
    "    print(\"Please ensure 'mvp_data_prep.ipynb' has been run successfully and paths are correct.\")\n",
    "else:\n",
    "    print(f\"Loading data from: {data_base_dir}\")\n",
    "\n",
    "BATCH_SIZE = 32 # Adjust based on GPU memory\n",
    "IMG_HEIGHT, IMG_WIDTH = IMG_SIZE, IMG_SIZE # From models.py\n",
    "\n",
    "# Create datasets\n",
    "train_ds_raw = create_tf_dataset(train_data_dir, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, shuffle=True)\n",
    "val_ds_raw = create_tf_dataset(val_data_dir, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, shuffle=False)\n",
    "test_ds_raw = create_tf_dataset(test_data_dir, (IMG_HEIGHT, IMG_WIDTH), BATCH_SIZE, shuffle=False) # For final eval\n",
    "\n",
    "# Get class names\n",
    "class_names = get_class_names(train_data_dir)\n",
    "num_classes = len(class_names)\n",
    "print(f\"Found {num_classes} classes: {class_names}\")\n",
    "\n",
    "# Apply preprocessing and augmentation\n",
    "train_ds = prepare_dataset(train_ds_raw, IMG_HEIGHT, IMG_WIDTH, augment=True)\n",
    "val_ds = prepare_dataset(val_ds_raw, IMG_HEIGHT, IMG_WIDTH, augment=False)\n",
    "test_ds = prepare_dataset(test_ds_raw, IMG_HEIGHT, IMG_WIDTH, augment=False)\n",
    "\n",
    "print(\"Datasets created and prepared.\")\n",
    "\n",
    "# Optional: Visualize a batch\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\")) # Need uint8 for imshow\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Model Definition and Compilation\n",
    "\n",
    "model = build_fp32_efficientnet_model(num_classes)\n",
    "model.summary()\n",
    "\n",
    "# Define alpha weights for Weighted Focal Loss (MVP: just a placeholder example)\n",
    "# In a real scenario, you'd calculate these based on your actual class frequencies.\n",
    "# For MVP, let's just make a dummy array.\n",
    "dummy_alpha = np.ones(num_classes) * 0.5 # Example: all classes get 0.5 weight initially\n",
    "# For actual weighted focal loss, you'd calculate:\n",
    "# class_counts = np.bincount(tf.concat([labels for _, labels in train_ds_raw.unbatch()], axis=0).numpy())\n",
    "# total_samples = np.sum(class_counts)\n",
    "# class_frequencies = class_counts / total_samples\n",
    "# inverse_frequencies = 1.0 / class_frequencies\n",
    "# alpha_weights = inverse_frequencies / np.sum(inverse_frequencies) # Normalize to sum to 1\n",
    "# You might want to smooth these or cap extreme values.\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=WeightedFocalLoss(gamma=2.0, alpha=dummy_alpha), # Use your custom loss\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model defined and compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Model Training\n",
    "\n",
    "EPOCHS = 10 # Start with a small number for MVP to quickly see results\n",
    "\n",
    "# Define callbacks\n",
    "# ModelCheckpoint to save the best model weights\n",
    "checkpoint_filepath = os.path.join(project_root, 'trained_models', 'fp32_mvp_best_model.h5')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False, # Save the entire model\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping to prevent overfitting\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3, # Number of epochs with no improvement after which training will be stopped.\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[model_checkpoint_callback, early_stopping_callback]\n",
    ")\n",
    "\n",
    "print(\"Training complete. Model saved to:\", checkpoint_filepath)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Basic Model Evaluation on Test Set\n",
    "\n",
    "print(\"\\n--- Evaluating MVP Model on Test Set ---\")\n",
    "# Load the best saved model for evaluation\n",
    "best_model = tf.keras.models.load_model(\n",
    "    checkpoint_filepath,\n",
    "    custom_objects={'WeightedFocalLoss': WeightedFocalLoss} # Needed if your custom loss is not saved by name\n",
    ")\n",
    "loss, accuracy = best_model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save class names for later use (e.g., in inference)\n",
    "class_names_path = os.path.join(project_root, 'data', 'class_names.txt')\n",
    "with open(class_names_path, 'w') as f:\n",
    "    for name in class_names:\n",
    "        f.write(f\"{name}\\n\")\n",
    "print(f\"Class names saved to: {class_names_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Mock Inference Example with Saved Model\n",
    "\n",
    "# Get one image from the test set for demonstration\n",
    "for images, labels in test_ds.take(1):\n",
    "    sample_image = images[0]\n",
    "    sample_label = labels[0]\n",
    "    break\n",
    "\n",
    "# Add a batch dimension to the single image\n",
    "sample_image_batch = tf.expand_dims(sample_image, axis=0)\n",
    "\n",
    "# Make prediction\n",
    "predictions = best_model.predict(sample_image_batch)\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "predicted_confidence = np.max(predictions[0])\n",
    "\n",
    "print(f\"\\n--- Mock Inference ---\")\n",
    "print(f\"True Class: {class_names[sample_label.numpy()]}\")\n",
    "print(f\"Predicted Class: {class_names[predicted_class_idx]}\")\n",
    "print(f\"Predicted Confidence: {predicted_confidence:.4f}\")\n",
    "\n",
    "plt.imshow(sample_image.numpy().astype(\"uint8\"))\n",
    "plt.title(f\"Predicted: {class_names[predicted_class_idx]} ({predicted_confidence:.2f})\\nTrue: {class_names[sample_label.numpy()]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModule 1 FP32 MVP training and basic evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
