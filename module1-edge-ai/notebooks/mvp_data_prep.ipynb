{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb732219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment and Mount Google Drive\n",
    "# This cell sets up necessary libraries and connects to your Google Drive.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm # For progress bars\n",
    "import zipfile\n",
    "import requests # For Pythonic download alternative (not used directly here, but good to have)\n",
    "\n",
    "# Install split-folders library - essential for stratified splitting\n",
    "!pip install split-folders tqdm\n",
    "\n",
    "from splitfolders import ratio\n",
    "\n",
    "# Mount Google Drive (REQUIRED for persistent storage of large files)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Environment setup complete and Google Drive mounted.\")\n",
    "\n",
    "# --- DEFINE YOUR GOOGLE DRIVE PROJECT DATA ROOT ---\n",
    "# This MUST match the path you set in 'drive_setup_project_data_dirs.ipynb'\n",
    "GOOGLE_DRIVE_PROJECT_ROOT = '/content/drive/MyDrive/AgroAI_Project_Data' # <--- ENSURE THIS MATCHES YOUR SETUP!\n",
    "if not os.path.exists(GOOGLE_DRIVE_PROJECT_ROOT):\n",
    "    raise FileNotFoundError(f\"Google Drive project root not found: {GOOGLE_DRIVE_PROJECT_ROOT}. Please run 'drive_setup_project_data_dirs.ipynb' first.\")\n",
    "print(f\"Google Drive project root (for data storage): {GOOGLE_DRIVE_PROJECT_ROOT}\")\n",
    "\n",
    "# --- DEFINE PROJECT-SPECIFIC DATA PATHS WITHIN GOOGLE DRIVE ---\n",
    "# These paths are where Module 1's large data and models will be stored persistently.\n",
    "MODULE1_DRIVE_DATA_DIR = os.path.join(GOOGLE_DRIVE_PROJECT_ROOT, 'module1_edge_ai', 'data')\n",
    "MODULE1_DRIVE_MODELS_DIR = os.path.join(GOOGLE_DRIVE_PROJECT_ROOT, 'module1_edge_ai', 'trained_models')\n",
    "\n",
    "# Ensure these directories exist (they should, if drive_setup_project_data_dirs.ipynb was run)\n",
    "os.makedirs(MODULE1_DRIVE_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODULE1_DRIVE_MODELS_DIR, exist_ok=True) # Ensure models dir is also there\n",
    "print(f\"Module 1 data will be stored persistently in Drive at: {MODULE1_DRIVE_DATA_DIR}\")\n",
    "print(f\"Module 1 models will be stored persistently in Drive at: {MODULE1_DRIVE_MODELS_DIR}\")\n",
    "\n",
    "# Define where your raw PlantVillage ZIP will be downloaded *to* in Google Drive\n",
    "PLANTVILLAGE_ZIP_PATH_DRIVE = os.path.join(MODULE1_DRIVE_DATA_DIR, 'plantvillage_dataset.zip')\n",
    "\n",
    "# Define the source URL for the PlantVillage dataset\n",
    "PLANTVILLAGE_DOWNLOAD_URL = \"https://storage.googleapis.com/plantdata/PlantVillage.zip\"\n",
    "\n",
    "# Define the directory names for extracted and subset data within your Drive module data folder\n",
    "EXTRACTED_DATA_DIR = os.path.join(MODULE1_DRIVE_DATA_DIR, 'PlantVillage_Raw')\n",
    "SUBSET_OUTPUT_DIR = os.path.join(MODULE1_DRIVE_DATA_DIR, 'PlantVillage_Subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c81c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Download and Extract PlantVillage Dataset Directly to Google Drive\n",
    "# This cell handles getting the raw PlantVillage dataset and saving it persistently.\n",
    "\n",
    "print(f\"\\n--- Attempting to download PlantVillage dataset to Google Drive: {PLANTVILLAGE_ZIP_PATH_DRIVE} ---\")\n",
    "\n",
    "if not os.path.exists(PLANTVILLAGE_ZIP_PATH_DRIVE):\n",
    "    print(f\"Downloading from: {PLANTVILLAGE_DOWNLOAD_URL}\")\n",
    "    # Using !wget for direct download to Google Drive path\n",
    "    !wget -q {PLANTVILLAGE_DOWNLOAD_URL} -O \"{PLANTVILLAGE_ZIP_PATH_DRIVE}\"\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(\"PlantVillage zip already exists in Google Drive. Skipping download.\")\n",
    "\n",
    "# Verify that the ZIP file exists before proceeding\n",
    "if not os.path.exists(PLANTVILLAGE_ZIP_PATH_DRIVE):\n",
    "    raise FileNotFoundError(f\"ERROR: PlantVillage dataset ZIP not found at {PLANTVILLAGE_ZIP_PATH_DRIVE} after download attempt.\")\n",
    "\n",
    "# Extract the dataset\n",
    "print(f\"\\n--- Extracting dataset from {PLANTVILLAGE_ZIP_PATH_DRIVE} to {EXTRACTED_DATA_DIR} ---\")\n",
    "if os.path.exists(EXTRACTED_DATA_DIR):\n",
    "    print(f\"Existing extraction found at {EXTRACTED_DATA_DIR}. Deleting for fresh extraction...\")\n",
    "    shutil.rmtree(EXTRACTED_DATA_DIR) # Clear previous extraction for idempotence\n",
    "os.makedirs(EXTRACTED_DATA_DIR, exist_ok=True) # Recreate the directory\n",
    "\n",
    "with zipfile.ZipFile(PLANTVILLAGE_ZIP_PATH_DRIVE, 'r') as zip_ref:\n",
    "    # Use tqdm for a progress bar during extraction\n",
    "    for member in tqdm(zip_ref.infolist(), desc='Extracting '):\n",
    "        try:\n",
    "            zip_ref.extract(member, EXTRACTED_DATA_DIR)\n",
    "        except zipfile.error as e:\n",
    "            print(f\"Error extracting {member.filename}: {e}\")\n",
    "            continue\n",
    "print(\"Extraction complete.\")\n",
    "\n",
    "# Verify and set the actual root directory within the extracted data\n",
    "# The zip might extract into a subdirectory named 'PlantVillage'\n",
    "extracted_contents = os.listdir(EXTRACTED_DATA_DIR)\n",
    "if 'PlantVillage' in extracted_contents and os.path.isdir(os.path.join(EXTRACTED_DATA_DIR, 'PlantVillage')):\n",
    "    ORIGINAL_DATA_ROOT = os.path.join(EXTRACTED_DATA_DIR, 'PlantVillage')\n",
    "else:\n",
    "    # If not 'PlantVillage', assume the class folders are directly under EXTRACTED_DATA_DIR\n",
    "    ORIGINAL_DATA_ROOT = EXTRACTED_DATA_DIR\n",
    "\n",
    "print(f\"Original dataset root for splitting (containing class folders): {ORIGINAL_DATA_ROOT}\")\n",
    "if not os.path.exists(ORIGINAL_DATA_ROOT) or not os.listdir(ORIGINAL_DATA_ROOT):\n",
    "    raise FileNotFoundError(f\"ERROR: Original data root '{ORIGINAL_DATA_ROOT}' not found or is empty after extraction. Please check the zip content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9403fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Create Train, Validation, Test Subset\n",
    "# This cell creates the stratified train/validation/test split into the desired structure.\n",
    "\n",
    "# Clear existing subset directory if it exists to ensure a clean split\n",
    "if os.path.exists(SUBSET_OUTPUT_DIR):\n",
    "    print(f\"Removing existing subset directory: {SUBSET_OUTPUT_DIR}\")\n",
    "    shutil.rmtree(SUBSET_OUTPUT_DIR)\n",
    "os.makedirs(SUBSET_OUTPUT_DIR, exist_ok=True) # Recreate the directory\n",
    "\n",
    "print(f\"\\n--- Creating train/val/test split into {SUBSET_OUTPUT_DIR} ---\")\n",
    "# Use split-folders to create the train/val/test split\n",
    "# ratio = (train, val, test)\n",
    "# seed for reproducibility\n",
    "# group_prefix=None is suitable for datasets where class names are directly folder names\n",
    "ratio(\n",
    "    ORIGINAL_DATA_ROOT,\n",
    "    output=SUBSET_OUTPUT_DIR,\n",
    "    seed=1337, # Fixed seed for reproducibility\n",
    "    ratio=(0.7, 0.15, 0.15), # 70% train, 15% validation, 15% test\n",
    "    group_prefix=None\n",
    ")\n",
    "\n",
    "print(\"\\nDataset splitting complete. Generated directory structure (in Google Drive):\")\n",
    "# List the contents of the newly created train/val/test directories\n",
    "for split_folder in ['train', 'val', 'test']:\n",
    "    path = os.path.join(SUBSET_OUTPUT_DIR, split_folder)\n",
    "    print(f\"\\nContents of {path}:\")\n",
    "    if os.path.exists(path):\n",
    "        # List first few class subdirectories to show structure\n",
    "        class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "        print(f\"  Total classes: {len(class_dirs)}\")\n",
    "        print(\"  Sample class directories:\", sorted(class_dirs)[:5], \"...\")\n",
    "    else:\n",
    "        print(f\"  {split_folder} directory not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e653bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Verify Data Counts (Optional but Recommended)\n",
    "# This cell helps verify the number of images in each split for sanity check.\n",
    "\n",
    "print(\"\\n--- Verifying Image Counts in Each Split ---\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(SUBSET_OUTPUT_DIR, split)\n",
    "    if os.path.exists(split_path):\n",
    "        total_images = 0\n",
    "        num_classes = 0\n",
    "        print(f\"\\n{split.upper()} set located at: {split_path}\")\n",
    "        for class_name in sorted(os.listdir(split_path)):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                num_images = len(os.listdir(class_path))\n",
    "                # print(f\"  - {class_name}: {num_images} images\") # Uncomment for verbose class-wise counts\n",
    "                total_images += num_images\n",
    "                num_classes += 1\n",
    "        print(f\"Total images in {split.upper()} set: {total_images} across {num_classes} classes.\")\n",
    "    else:\n",
    "        print(f\"Warning: {split.upper()} directory not found at {split_path}\")\n",
    "\n",
    "print(\"\\nModule 1 MVP data preparation complete! The structured dataset is ready for training, persistently stored in Google Drive.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
