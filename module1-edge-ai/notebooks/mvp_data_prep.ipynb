{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb732219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup Environment and Mount Google Drive\n",
    "# This cell sets up necessary libraries and connects to your Google Drive\n",
    "# where you might store the PlantVillage dataset or clone your repo.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from tqdm import tqdm # For progress bars\n",
    "import zipfile\n",
    "\n",
    "# Install split-folders library - essential for stratified splitting\n",
    "!pip install split-folders tqdm\n",
    "\n",
    "from splitfolders import ratio\n",
    "\n",
    "# Mount Google Drive (if you store your dataset or project repo there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Environment setup complete and Google Drive mounted.\")\n",
    "\n",
    "# Define your project root in Colab.\n",
    "# Assuming your 'agro-ai-copilot' repo is cloned into /content/drive/MyDrive/agro-ai-copilot\n",
    "PROJECT_ROOT_DIR = '/content/drive/MyDrive/agro-ai-copilot/module1-edge-ai'\n",
    "\n",
    "# Fallback for temporary Colab runtime if repo is not found on Drive.\n",
    "# In this case, you'll need to manually manage copying data or re-running git clone.\n",
    "if not os.path.exists(PROJECT_ROOT_DIR):\n",
    "    print(f\"Warning: Project root '{PROJECT_ROOT_DIR}' not found. Using local Colab path.\")\n",
    "    PROJECT_ROOT_DIR = '/content/module1-edge-ai_local' # This will be created locally in Colab\n",
    "    os.makedirs(PROJECT_ROOT_DIR, exist_ok=True)\n",
    "\n",
    "# Create the specific data directory within module1-edge-ai\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT_DIR, 'data')\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"Project data directory set to: {DATA_DIR}\")\n",
    "\n",
    "# Define where your raw PlantVillage ZIP is located or will be downloaded.\n",
    "# Option 1: Path if stored in Google Drive (adjust this path if needed)\n",
    "PLANTVILLAGE_ZIP_PATH_DRIVE = '/content/drive/MyDrive/plantvillage dataset.zip' # <--- ADJUST THIS PATH if your zip is named differently or elsewhere!\n",
    "\n",
    "# Option 2: Download directly from a common public mirror (recommended for ease in Colab)\n",
    "# This URL points to a compressed version often found publicly.\n",
    "PLANTVILLAGE_DOWNLOAD_URL = \"https://storage.googleapis.com/plantdata/PlantVillage.zip\"\n",
    "PLANTVILLAGE_ZIP_PATH_COLAB = os.path.join(DATA_DIR, 'plantvillage_dataset.zip') # Name for downloaded file\n",
    "\n",
    "# Define the directory where the extracted dataset will live temporarily\n",
    "# This is the raw dataset after unzipping, before splitting.\n",
    "EXTRACTED_DATA_DIR = os.path.join(DATA_DIR, 'PlantVillage_Raw')\n",
    "\n",
    "# Define the directory where the final train/val/test subsets will be placed\n",
    "SUBSET_OUTPUT_DIR = os.path.join(DATA_DIR, 'PlantVillage_Subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c81c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. Download and Extract PlantVillage Dataset\n",
    "# This cell handles getting the raw PlantVillage dataset.\n",
    "# It prioritizes checking Google Drive first, then defaults to downloading.\n",
    "\n",
    "SOURCE_ZIP_PATH = None\n",
    "\n",
    "# Try using dataset from Google Drive first\n",
    "print(f\"\\n--- Attempting to use PlantVillage dataset from Google Drive ---\")\n",
    "if os.path.exists(PLANTVILLAGE_ZIP_PATH_DRIVE):\n",
    "    print(f\"Using zip from Google Drive: {PLANTVILLAGE_ZIP_PATH_DRIVE}\")\n",
    "    SOURCE_ZIP_PATH = PLANTVILLAGE_ZIP_PATH_DRIVE\n",
    "else:\n",
    "    print(f\"PlantVillage zip not found at {PLANTVILLAGE_ZIP_PATH_DRIVE}.\")\n",
    "    print(f\"Attempting to download to Colab runtime from: {PLANTVILLAGE_DOWNLOAD_URL}\")\n",
    "    if not os.path.exists(PLANTVILLAGE_ZIP_PATH_COLAB):\n",
    "        !wget -q {PLANTVILLAGE_DOWNLOAD_URL} -O \"{PLANTVILLAGE_ZIP_PATH_COLAB}\"\n",
    "        print(\"Download complete.\")\n",
    "    else:\n",
    "        print(\"PlantVillage zip already exists in Colab runtime. Skipping download.\")\n",
    "    SOURCE_ZIP_PATH = PLANTVILLAGE_ZIP_PATH_COLAB\n",
    "\n",
    "if SOURCE_ZIP_PATH is None or not os.path.exists(SOURCE_ZIP_PATH):\n",
    "    raise FileNotFoundError(\"Could not find or download PlantVillage dataset ZIP. Please check paths or URLs.\")\n",
    "\n",
    "\n",
    "# Extract the dataset\n",
    "print(f\"\\n--- Extracting dataset from {SOURCE_ZIP_PATH} to {EXTRACTED_DATA_DIR} ---\")\n",
    "if os.path.exists(EXTRACTED_DATA_DIR):\n",
    "    print(f\"Existing extraction found at {EXTRACTED_DATA_DIR}. Deleting for fresh extraction...\")\n",
    "    shutil.rmtree(EXTRACTED_DATA_DIR) # Clear previous extraction for idempotence\n",
    "os.makedirs(EXTRACTED_DATA_DIR, exist_ok=True) # Recreate the directory\n",
    "\n",
    "with zipfile.ZipFile(SOURCE_ZIP_PATH, 'r') as zip_ref:\n",
    "    # Use tqdm for a progress bar during extraction\n",
    "    for member in tqdm(zip_ref.infolist(), desc='Extracting '):\n",
    "        try:\n",
    "            zip_ref.extract(member, EXTRACTED_DATA_DIR)\n",
    "        except zipfile.error as e:\n",
    "            print(f\"Error extracting {member.filename}: {e}\")\n",
    "            continue\n",
    "print(\"Extraction complete.\")\n",
    "\n",
    "# Verify and set the actual root directory within the extracted data\n",
    "# The zip might extract into a subdirectory named 'PlantVillage'\n",
    "extracted_contents = os.listdir(EXTRACTED_DATA_DIR)\n",
    "if 'PlantVillage' in extracted_contents and os.path.isdir(os.path.join(EXTRACTED_DATA_DIR, 'PlantVillage')):\n",
    "    ORIGINAL_DATA_ROOT = os.path.join(EXTRACTED_DATA_DIR, 'PlantVillage')\n",
    "else:\n",
    "    # If not 'PlantVillage', assume the class folders are directly under EXTRACTED_DATA_DIR\n",
    "    ORIGINAL_DATA_ROOT = EXTRACTED_DATA_DIR\n",
    "\n",
    "print(f\"Original dataset root for splitting (containing class folders): {ORIGINAL_DATA_ROOT}\")\n",
    "if not os.path.exists(ORIGINAL_DATA_ROOT) or not os.listdir(ORIGINAL_DATA_ROOT):\n",
    "    raise FileNotFoundError(f\"ERROR: Original data root '{ORIGINAL_DATA_ROOT}' not found or is empty after extraction. Please check the zip content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9403fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Create Train, Validation, Test Subset\n",
    "# This cell creates the stratified train/validation/test split into the desired structure.\n",
    "\n",
    "# Clear existing subset directory if it exists to ensure a clean split\n",
    "if os.path.exists(SUBSET_OUTPUT_DIR):\n",
    "    print(f\"Removing existing subset directory: {SUBSET_OUTPUT_DIR}\")\n",
    "    shutil.rmtree(SUBSET_OUTPUT_DIR)\n",
    "os.makedirs(SUBSET_OUTPUT_DIR, exist_ok=True) # Recreate the directory\n",
    "\n",
    "print(f\"\\n--- Creating train/val/test split into {SUBSET_OUTPUT_DIR} ---\")\n",
    "# Use split-folders to create the train/val/test split\n",
    "# ratio = (train, val, test)\n",
    "# seed for reproducibility\n",
    "# group_prefix=None is suitable for datasets where class names are directly folder names\n",
    "ratio(\n",
    "    ORIGINAL_DATA_ROOT,\n",
    "    output=SUBSET_OUTPUT_DIR,\n",
    "    seed=1337, # Fixed seed for reproducibility\n",
    "    ratio=(0.7, 0.15, 0.15), # 70% train, 15% validation, 15% test\n",
    "    group_prefix=None\n",
    ")\n",
    "\n",
    "print(\"\\nDataset splitting complete. Generated directory structure:\")\n",
    "# List the contents of the newly created train/val/test directories\n",
    "for split_folder in ['train', 'val', 'test']:\n",
    "    path = os.path.join(SUBSET_OUTPUT_DIR, split_folder)\n",
    "    print(f\"\\nContents of {path}:\")\n",
    "    if os.path.exists(path):\n",
    "        # List first few class subdirectories to show structure\n",
    "        class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "        print(f\"  Total classes: {len(class_dirs)}\")\n",
    "        print(\"  Sample class directories:\", sorted(class_dirs)[:5], \"...\")\n",
    "    else:\n",
    "        print(f\"  {split_folder} directory not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e653bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Verify Data Counts (Optional but Recommended)\n",
    "# This cell helps verify the number of images in each split for sanity check.\n",
    "\n",
    "print(\"\\n--- Verifying Image Counts in Each Split ---\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(SUBSET_OUTPUT_DIR, split)\n",
    "    if os.path.exists(split_path):\n",
    "        total_images = 0\n",
    "        num_classes = 0\n",
    "        print(f\"\\n{split.upper()} set located at: {split_path}\")\n",
    "        for class_name in sorted(os.listdir(split_path)):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                num_images = len(os.listdir(class_path))\n",
    "                # print(f\"  - {class_name}: {num_images} images\") # Uncomment for verbose class-wise counts\n",
    "                total_images += num_images\n",
    "                num_classes += 1\n",
    "        print(f\"Total images in {split.upper()} set: {total_images} across {num_classes} classes.\")\n",
    "    else:\n",
    "        print(f\"Warning: {split.upper()} directory not found at {split_path}\")\n",
    "\n",
    "print(\"\\nModule 1 MVP data preparation complete! The structured dataset is ready for training.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
