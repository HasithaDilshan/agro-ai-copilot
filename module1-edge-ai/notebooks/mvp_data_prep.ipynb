{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cb732219",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb732219",
        "outputId": "55aa6eb4-f407-4eb9-ed95-00b9f365620a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Environment setup complete and Google Drive mounted.\n",
            "Google Drive project root (for data storage): /content/drive/MyDrive/AgroAI_Project_Data\n",
            "Module 1 data will be stored persistently in Drive at: /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data\n",
            "Module 1 models will be stored persistently in Drive at: /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/trained_models\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Setup Environment and Mount Google Drive\n",
        "# This cell sets up necessary libraries and connects to your Google Drive.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm # For progress bars\n",
        "import zipfile\n",
        "import requests # For Pythonic download alternative (not used directly here, but good to have)\n",
        "\n",
        "# Install split-folders library - essential for stratified splitting\n",
        "!pip install split-folders tqdm\n",
        "\n",
        "from splitfolders import ratio\n",
        "\n",
        "# Mount Google Drive (REQUIRED for persistent storage of large files)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Environment setup complete and Google Drive mounted.\")\n",
        "\n",
        "# --- DEFINE YOUR GOOGLE DRIVE PROJECT DATA ROOT ---\n",
        "# This MUST match the path you set in 'drive_setup_project_data_dirs.ipynb'\n",
        "GOOGLE_DRIVE_PROJECT_ROOT = '/content/drive/MyDrive/AgroAI_Project_Data' # <--- ENSURE THIS MATCHES YOUR SETUP!\n",
        "if not os.path.exists(GOOGLE_DRIVE_PROJECT_ROOT):\n",
        "    raise FileNotFoundError(f\"Google Drive project root not found: {GOOGLE_DRIVE_PROJECT_ROOT}. Please run 'drive_setup_project_data_dirs.ipynb' first.\")\n",
        "print(f\"Google Drive project root (for data storage): {GOOGLE_DRIVE_PROJECT_ROOT}\")\n",
        "\n",
        "# --- DEFINE PROJECT-SPECIFIC DATA PATHS WITHIN GOOGLE DRIVE ---\n",
        "# These paths are where Module 1's large data and models will be stored persistently.\n",
        "MODULE1_DRIVE_DATA_DIR = os.path.join(GOOGLE_DRIVE_PROJECT_ROOT, 'module1_edge_ai', 'data')\n",
        "MODULE1_DRIVE_MODELS_DIR = os.path.join(GOOGLE_DRIVE_PROJECT_ROOT, 'module1_edge_ai', 'trained_models')\n",
        "\n",
        "# Ensure these directories exist (they should, if drive_setup_project_data_dirs.ipynb was run)\n",
        "os.makedirs(MODULE1_DRIVE_DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODULE1_DRIVE_MODELS_DIR, exist_ok=True) # Ensure models dir is also there\n",
        "print(f\"Module 1 data will be stored persistently in Drive at: {MODULE1_DRIVE_DATA_DIR}\")\n",
        "print(f\"Module 1 models will be stored persistently in Drive at: {MODULE1_DRIVE_MODELS_DIR}\")\n",
        "\n",
        "# Define where your raw PlantVillage ZIP will be downloaded *to* in Google Drive\n",
        "PLANTVILLAGE_ZIP_PATH_DRIVE = os.path.join(MODULE1_DRIVE_DATA_DIR, 'plantvillage_dataset.zip')\n",
        "\n",
        "# Define the source URL for the PlantVillage dataset\n",
        "PLANTVILLAGE_DOWNLOAD_URL = \"https://storage.googleapis.com/plantdata/PlantVillage.zip\"\n",
        "\n",
        "# Define the directory names for extracted and subset data within your Drive module data folder\n",
        "EXTRACTED_DATA_DIR = os.path.join(MODULE1_DRIVE_DATA_DIR, 'PlantVillage_Raw')\n",
        "SUBSET_OUTPUT_DIR = os.path.join(MODULE1_DRIVE_DATA_DIR, 'PlantVillage_Subset')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3faa364",
        "outputId": "546bbbb3-3f93-4fd3-8d55-94a493c2fc53"
      },
      "source": [
        "# @title 2.1. Clone PlantVillage Dataset from Git Repository\n",
        "# This cell clones the dataset from the specified Git repository instead of downloading a zip.\n",
        "\n",
        "GIT_REPO_URL = \"https://github.com/gabrieldgf4/PlantVillage-Dataset.git\"\n",
        "REPO_CLONE_PATH = os.path.join(MODULE1_DRIVE_DATA_DIR, 'PlantVillage_GitClone')\n",
        "\n",
        "print(f\"\\n--- Attempting to clone PlantVillage dataset from Git: {GIT_REPO_URL} ---\")\n",
        "\n",
        "if os.path.exists(REPO_CLONE_PATH):\n",
        "    print(f\"Existing clone found at {REPO_CLONE_PATH}. Removing for fresh clone...\")\n",
        "    shutil.rmtree(REPO_CLONE_PATH) # Clear previous clone\n",
        "os.makedirs(REPO_CLONE_PATH, exist_ok=True) # Ensure parent directory exists\n",
        "\n",
        "# Clone the repository\n",
        "!git clone {GIT_REPO_URL} \"{REPO_CLONE_PATH}\"\n",
        "\n",
        "print(\"Git cloning complete.\")\n",
        "\n",
        "# Set the ORIGINAL_DATA_ROOT to the location of the cloned data\n",
        "# Assuming the images are directly within a subdirectory of the cloned repo, e.g., 'PlantVillage-Dataset/dataset'\n",
        "# You might need to inspect the cloned directory structure and adjust this path\n",
        "# For now, let's assume the class folders are directly within the cloned repo root or a subdirectory\n",
        "# We'll need to verify this after execution.\n",
        "# Let's make a reasonable guess based on typical repository structure.\n",
        "# If the data is in a folder named 'dataset' within the cloned repo:\n",
        "ASSUMED_DATA_SUBDIR = 'dataset'\n",
        "ORIGINAL_DATA_ROOT = os.path.join(REPO_CLONE_PATH, ASSUMED_DATA_SUBDIR)\n",
        "\n",
        "# If the data is directly in the cloned repo root, use this instead:\n",
        "# ORIGINAL_DATA_ROOT = REPO_CLONE_PATH\n",
        "\n",
        "\n",
        "print(f\"Assumed original dataset root for splitting (containing class folders): {ORIGINAL_DATA_ROOT}\")\n",
        "\n",
        "# Basic check to see if the assumed path exists and has content\n",
        "if not os.path.exists(ORIGINAL_DATA_ROOT) or not os.listdir(ORIGINAL_DATA_ROOT):\n",
        "     print(f\"WARNING: Assumed data root '{ORIGINAL_DATA_ROOT}' not found or is empty.\")\n",
        "     print(\"Please inspect the contents of the cloned repository at:\")\n",
        "     print(REPO_CLONE_PATH)\n",
        "     print(\"And manually set the correct ORIGINAL_DATA_ROOT path based on the actual directory structure.\")\n",
        "else:\n",
        "    print(\"Assumed data root seems valid. Proceeding with splitting (Cell 3).\")\n",
        "\n",
        "# Note: The splitting cell (Cell 3) still expects ORIGINAL_DATA_ROOT to point to the directory\n",
        "# containing the class subfolders. You might need to manually update the path in Cell 3\n",
        "# if the structure of the cloned repository is different than expected."
      ],
      "id": "c3faa364",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Attempting to clone PlantVillage dataset from Git: https://github.com/gabrieldgf4/PlantVillage-Dataset.git ---\n",
            "Existing clone found at /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_GitClone. Removing for fresh clone...\n",
            "Cloning into '/content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_GitClone'...\n",
            "remote: Enumerating objects: 54511, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 54511 (delta 36), reused 0 (delta 0), pack-reused 54403 (from 1)\u001b[K\n",
            "Receiving objects: 100% (54511/54511), 806.27 MiB | 12.75 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "Updating files: 100% (54306/54306), done.\n",
            "Git cloning complete.\n",
            "Assumed original dataset root for splitting (containing class folders): /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_GitClone/dataset\n",
            "WARNING: Assumed data root '/content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_GitClone/dataset' not found or is empty.\n",
            "Please inspect the contents of the cloned repository at:\n",
            "/content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_GitClone\n",
            "And manually set the correct ORIGINAL_DATA_ROOT path based on the actual directory structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "89c81c0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89c81c0a",
        "outputId": "49c97f35-37ee-4221-c164-56d49a0b2e5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n",
            "Original dataset root for splitting (containing class folders): /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Raw\n"
          ]
        }
      ],
      "source": [
        "# @title 2. Download and Extract PlantVillage Dataset Directly to Google Drive\n",
        "# This cell handles getting the raw PlantVillage dataset and saving it persistently.\n",
        "\n",
        "# print(f\"\\n--- Attempting to download PlantVillage dataset to Google Drive: {PLANTVILLAGE_ZIP_PATH_DRIVE} ---\")\n",
        "\n",
        "# if not os.path.exists(PLANTVILLAGE_ZIP_PATH_DRIVE):\n",
        "#     print(f\"Downloading from: {PLANTVILLAGE_DOWNLOAD_URL}\")\n",
        "#     # Using !wget for direct download to Google Drive path\n",
        "#     !wget -q {PLANTVILLAGE_DOWNLOAD_URL} -O \"{PLANTVILLAGE_ZIP_PATH_DRIVE}\"\n",
        "#     print(\"Download complete.\")\n",
        "# else:\n",
        "#     print(\"PlantVillage zip already exists in Google Drive. Skipping download.\")\n",
        "\n",
        "# # Verify that the ZIP file exists before proceeding\n",
        "# if not os.path.exists(PLANTVILLAGE_ZIP_PATH_DRIVE):\n",
        "#     raise FileNotFoundError(f\"ERROR: PlantVillage dataset ZIP not found at {PLANTVILLAGE_ZIP_PATH_DRIVE} after download attempt.\")\n",
        "\n",
        "# # Extract the dataset\n",
        "# print(f\"\\n--- Extracting dataset from {PLANTVILLAGE_ZIP_PATH_DRIVE} to {EXTRACTED_DATA_DIR} ---\")\n",
        "# if os.path.exists(EXTRACTED_DATA_DIR):\n",
        "#     print(f\"Existing extraction found at {EXTRACTED_DATA_DIR}. Deleting for fresh extraction...\")\n",
        "#     shutil.rmtree(EXTRACTED_DATA_DIR) # Clear previous extraction for idempotence\n",
        "# os.makedirs(EXTRACTED_DATA_DIR, exist_ok=True) # Recreate the directory\n",
        "\n",
        "# with zipfile.ZipFile(PLANTVILLAGE_ZIP_PATH_DRIVE, 'r') as zip_ref:\n",
        "#     # Use tqdm for a progress bar during extraction\n",
        "#     for member in tqdm(zip_ref.infolist(), desc='Extracting '):\n",
        "#         try:\n",
        "#             zip_ref.extract(member, EXTRACTED_DATA_DIR)\n",
        "#         except zipfile.error as e:\n",
        "#             print(f\"Error extracting {member.filename}: {e}\")\n",
        "#             continue\n",
        "print(\"Extraction complete.\")\n",
        "\n",
        "# Verify and set the actual root directory within the extracted data\n",
        "# The zip might extract into a subdirectory named 'PlantVillage'\n",
        "extracted_contents = os.listdir(EXTRACTED_DATA_DIR)\n",
        "if 'PlantVillage' in extracted_contents and os.path.isdir(os.path.join(EXTRACTED_DATA_DIR, 'PlantVillage')):\n",
        "    ORIGINAL_DATA_ROOT = os.path.join(EXTRACTED_DATA_DIR, 'PlantVillage')\n",
        "else:\n",
        "    # If not 'PlantVillage', assume the class folders are directly under EXTRACTED_DATA_DIR\n",
        "    ORIGINAL_DATA_ROOT = EXTRACTED_DATA_DIR\n",
        "\n",
        "print(f\"Original dataset root for splitting (containing class folders): {ORIGINAL_DATA_ROOT}\")\n",
        "if not os.path.exists(ORIGINAL_DATA_ROOT) or not os.listdir(ORIGINAL_DATA_ROOT):\n",
        "    raise FileNotFoundError(f\"ERROR: Original data root '{ORIGINAL_DATA_ROOT}' not found or is empty after extraction. Please check the zip content.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6e9403fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e9403fc",
        "outputId": "708343e5-83b5-4d9f-e1f2-1de582bdbbf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating train/val/test split into /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 54310 files [26:14, 34.50 files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset splitting complete. Generated directory structure (in Google Drive):\n",
            "\n",
            "Contents of /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset/train:\n",
            "  Total classes: 40\n",
            "  Sample class directories: ['.git', 'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy'] ...\n",
            "\n",
            "Contents of /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset/val:\n",
            "  Total classes: 40\n",
            "  Sample class directories: ['.git', 'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy'] ...\n",
            "\n",
            "Contents of /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset/test:\n",
            "  Total classes: 40\n",
            "  Sample class directories: ['.git', 'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy'] ...\n"
          ]
        }
      ],
      "source": [
        "# @title 3. Create Train, Validation, Test Subset\n",
        "# This cell creates the stratified train/validation/test split into the desired structure.\n",
        "\n",
        "# Clear existing subset directory if it exists to ensure a clean split\n",
        "if os.path.exists(SUBSET_OUTPUT_DIR):\n",
        "    print(f\"Removing existing subset directory: {SUBSET_OUTPUT_DIR}\")\n",
        "    shutil.rmtree(SUBSET_OUTPUT_DIR)\n",
        "os.makedirs(SUBSET_OUTPUT_DIR, exist_ok=True) # Recreate the directory\n",
        "\n",
        "print(f\"\\n--- Creating train/val/test split into {SUBSET_OUTPUT_DIR} ---\")\n",
        "# Use split-folders to create the train/val/test split\n",
        "# ratio = (train, val, test)\n",
        "# seed for reproducibility\n",
        "# group_prefix=None is suitable for datasets where class names are directly folder names\n",
        "ratio(\n",
        "    ORIGINAL_DATA_ROOT,\n",
        "    output=SUBSET_OUTPUT_DIR,\n",
        "    seed=1337, # Fixed seed for reproducibility\n",
        "    ratio=(0.7, 0.15, 0.15), # 70% train, 15% validation, 15% test\n",
        "    group_prefix=None\n",
        ")\n",
        "\n",
        "print(\"\\nDataset splitting complete. Generated directory structure (in Google Drive):\")\n",
        "# List the contents of the newly created train/val/test directories\n",
        "for split_folder in ['train', 'val', 'test']:\n",
        "    path = os.path.join(SUBSET_OUTPUT_DIR, split_folder)\n",
        "    print(f\"\\nContents of {path}:\")\n",
        "    if os.path.exists(path):\n",
        "        # List first few class subdirectories to show structure\n",
        "        class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
        "        print(f\"  Total classes: {len(class_dirs)}\")\n",
        "        print(\"  Sample class directories:\", sorted(class_dirs)[:5], \"...\")\n",
        "    else:\n",
        "        print(f\"  {split_folder} directory not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6e653bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e653bc1",
        "outputId": "af6578dc-5d11-4c47-e11d-620a957ec31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Verifying Image Counts in Each Split ---\n",
            "\n",
            "TRAIN set located at: /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset/train\n",
            "Total images in TRAIN set: 38001 across 40 classes.\n",
            "\n",
            "VAL set located at: /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset/val\n",
            "Total images in VAL set: 8128 across 40 classes.\n",
            "\n",
            "TEST set located at: /content/drive/MyDrive/AgroAI_Project_Data/module1_edge_ai/data/PlantVillage_Subset/test\n",
            "Total images in TEST set: 8181 across 40 classes.\n",
            "\n",
            "Module 1 MVP data preparation complete! The structured dataset is ready for training, persistently stored in Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# @title 4. Verify Data Counts (Optional but Recommended)\n",
        "# This cell helps verify the number of images in each split for sanity check.\n",
        "\n",
        "print(\"\\n--- Verifying Image Counts in Each Split ---\")\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_path = os.path.join(SUBSET_OUTPUT_DIR, split)\n",
        "    if os.path.exists(split_path):\n",
        "        total_images = 0\n",
        "        num_classes = 0\n",
        "        print(f\"\\n{split.upper()} set located at: {split_path}\")\n",
        "        for class_name in sorted(os.listdir(split_path)):\n",
        "            class_path = os.path.join(split_path, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                num_images = len(os.listdir(class_path))\n",
        "                # print(f\"  - {class_name}: {num_images} images\") # Uncomment for verbose class-wise counts\n",
        "                total_images += num_images\n",
        "                num_classes += 1\n",
        "        print(f\"Total images in {split.upper()} set: {total_images} across {num_classes} classes.\")\n",
        "    else:\n",
        "        print(f\"Warning: {split.upper()} directory not found at {split_path}\")\n",
        "\n",
        "print(\"\\nModule 1 MVP data preparation complete! The structured dataset is ready for training, persistently stored in Google Drive.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}