# Mobile App: AgroAI Co-Pilot Frontend

## Core Objective
This Flutter application serves as the primary interface for Sri Lankan farmers to interact with the AgroAI Co-Pilot. The main goal is to translate complex AI-driven insights into simple, actionable advice through a reliable, intuitive, and visually elegant mobile experience. The app must build trust and confidence with its users.

---

## UI/UX Philosophy: "Elegant & Accessible"
The user interface must be designed with the end-user—the farmer—in mind. The design philosophy is not just about looking good; it's about being effective.

* **Clarity Above All:** The UI will use high-contrast colors, large, legible fonts (suitable for outdoor viewing), and spacious layouts. We will avoid clutter and information overload.
* **Domain-Specific Elegance:** The design should feel professional and trustworthy. We will use a clean color palette inspired by nature (greens, browns, blues) and intuitive icons that resonate with agriculture (e.g., a leaf for scanning, a calendar for planning, a sapling for growth).
* **Confidence Through Simplicity:** Complex data, like the environmental attribution score from Module 3, should be visualized using simple gauges or bar charts, not complicated graphs. The goal is to provide an "at-a-glance" understanding.
* **Offline-First:** The core diagnostic feature (**Module 1**) must be fully functional offline. The app will clearly communicate its connection status and indicate when it is fetching richer data from the cloud.
* **Localization:** The app must be built from the ground up to support English, Sinhala, and Tamil. All UI text will be handled through a localization layer.

---

## Key Features & User Flow
The application's features map directly to the project's core AI modules.

**1. The "Scan Plant" Feature (Module 1 & 2)**
* A prominent button on the home screen initiates the camera.
* After the user captures an image, the on-device TFLite model (**Module 1**) runs instantly.
* **Immediately**, the screen displays the top disease prediction and its calibrated confidence score (e.g., "Tomato Early Blight - 85% Confident"). This result is available offline.
* In the background, the image is uploaded to Firebase Storage for deeper analysis. A subtle loading indicator will be shown.
* Once the cloud analysis is complete, the view is enriched with the detailed advisory text generated by the graph-powered system (**Module 2**).

**2. The "Detailed Analysis" View (Module 3)**
* Accessible from the diagnosis result screen.
* Displays the predicted "Crop Stress Score" from **Module 3** as a simple gauge (e.g., 0-100 or Low/Medium/High).
* Shows the structured attribution score as a clear bar chart (e.g., Weather: 71%, Soil: 22%, Image: 7%). This helps the farmer understand the *why* behind the stress.

**3. The "Strategic Planner" Feature (Module 4)**
* A separate tab or section in the app.
* The user is prompted to select their risk preference ("Maximize Profit" vs. "Minimize Risk").
* The app calls a cloud function that runs the RL agent (**Module 4**).
* It then displays a clear recommendation for the next planting season, including the suggested crop, expected return, and risk level.

**4. History & Logbook**
* A simple, chronological list of all past scans.
* Each entry shows a thumbnail of the image, the diagnosis, and the date, allowing farmers to track the health of their crops over time.

---

## Technology Stack & Architecture
* **Framework:** Flutter
* **State Management:** Riverpod (Recommended for its scalability and testability)
* **Backend Integration:** `firebase_core`, `cloud_firestore`, `firebase_storage`, `cloud_functions`
* **On-Device AI:** `tflite_flutter_helper` for running the Module 1 model.
* **Localization:** `flutter_localizations` with a simple `intl` or JSON-based approach.
* **Architecture:** We will follow a **feature-first** folder structure to keep the code organized and scalable.
